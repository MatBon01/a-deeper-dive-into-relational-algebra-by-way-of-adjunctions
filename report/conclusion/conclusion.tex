\chapter{Conclusion}
\begin{comment}
Conclusions and Future Work
The project's conclusions should summarise the key insights that have been gained, be they positive or negative. For example, "The use of overloading in C++ provides a very elegant mechanism for transparent parallelisation of sequential programs", or "The overheads of linear-time n-body algorithms makes them computationally less efficient than O(n log n) algorithms for systems with less than 100000 particles". Avoid tedious personal reflections like "I learned a lot about C++ programming...". It is common to finish the report by listing ways in which the project can be taken further. This might, for example, be a plan for doing the project better if you could do a re-run, turning the project deliverables into a more polished end product, or extending the project into a programme for an MPhil or PhD.
\end{comment}
This chapter is a summary of the findings and original contributions this
project has. The contributions of the project are as follows:
\begin{itemize}
    \item An implementation of the database system described in
        \relalg{}~\cite{RelationalAlgebraByWayOfAdjunctions} in Haskell,
    \item The design of a \relation{JOINBENCH} relation,
    \item A low-level tool for the generation of synthetic databases,
    \item An evaluation of the performance of the aforementioned database
        systems.
\end{itemize}

The beginning of the project was successful with a crude implementation of the
database system described in the paper. The implementation was functional with
unit tests strengthening belief in correctness tests and ease of use during
benchmarks. Slight alterations had to be made to the implementation described by
\relalg{}, a handful of original contributions such as the definition of equalit
of bags were made and much effort was put into the integration of the system to form the
library defined in the code of this project. The library could further be
expanded through the definition of more keys and much real world modification
must be done to the design to make it useful in real world (for instance the
caching of indexed tables). The library defined is usable and functional for the
purposes of benchmarking and a good starting point for further expansion with
much room for many more query optimisations.

The \relation{JOINBENCH} relation is a carefully thought out combination of
benchmarking databases designe by other academics. I
believe that it exceeds at benchmarking equijoin and has a lot more depth than
the scope of this paper. It has attributes designed to investigate the effect of
different orders of products on the performance of equijoins and can be scaled
through select queries on the \relationAttribute{unique} attribute. There is no
doubt as to whether it has achieved its purpose in the scope of this paper.
After spotting trends it may be extended with a few more attributes or
supporting queries to investigate edge cases more thorougly.

The synthetic database generator gives users a low-level tool to generate very
customisable databases. The framework is very flexible yet prescriptive of
structure. For the benchmarking of this project, a wide array of different cell
types were defined and used to create the \relation{JOINBENCH} relation and
previous iterations of benchmarking databases. It has a capacity for both
qualitative and quantative data, however I have found it extremely useful on the
quantative side. Patterns and trends between cell values can be moderated
through cell composition or passing shared objects into constructors and is very
powerful for customisation of the result. In future this framework could be
exteneded to allow for a more user-friendly interaction, though care must be
taken as to not lose the flexibility that comes from the low-levelled nature of
the design. Furthermore, work may be made to make the framework more context
aware so that it may be used to generate more useful tools such as SQL commands
to create the database and Haskell parsers to read its output; similarly, care
must be taken not to lose the simplicity of the current solution and force users
to give irrelevant information to their usecase. This framework is a large
original contribution of this project.

Finally, although there is much room for more rigour in the statistical analysis
of results, benchmarking with the implementation above and this methodology has
produced extremely strong trends. It is clear that, as expected, indexed
equijoin needs to have a substantial number of tuples in order to become
effective over methods with a worse asymptotic complexity but reduced overhead.
Furthermore, comprehension equijoin does much better than expected and although
scales similar to product equijoin, does so with a significantly lower slope.
The trends behind indexed equijoin are more complicated, however, and rely
heavily on the number of and order of local products needed by the query. This
means that the performance increase of indexed equijoin heavily relies on the
query in question, though most real world situations would benefit from its
implementation as they are unlikely to fall into the same category as edge
cases. On the other hand, there are many query optimisations (such as a
preceding join) that are not considered in this project and future work may be
done to investigate how much of an effect these have on the efficiency of the
solutions. Furthermore, more work can be done to investigate the effect of
non-uniformly sized relations on such queries.

In conclusion, all the tools described in this paper were paramount to the
evaluation of the algorithms presented in the paper \relalg{}. Together they
produced results with relatively low standard deviations within their own
samples and clearly strong trends that are unlikely to be variable. Although
more work can be done to investigate the effect different contexts have on the
results I am confident that the findings of this paper will inform a strong
theoretical background and help inform any conjectures.
