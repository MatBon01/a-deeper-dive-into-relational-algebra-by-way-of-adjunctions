\section{Benchmarking databases}
Databases are pervasive to modern society and thus standards have arisen over
the last few decades to ensure that customers are able to pick their preferred
DBMS vendor.

At the top level, database benchmarks are classified into three categories: industry-standard, vendor and
customer-application \cite{PractitionersIntroduction}. 
These classifications are usually motivated by intention of the benchmark
instead of structure of the database management system; there is no shortage of
papers emphasising the importance of domain-specific benchmarks for applications
\cite{PractitionersIntroduction, BenchmarkHandbook} and depending on the
risk/performance tolerance of the application it may be necessary to consider
results from all three categories.

\paragraph{Vendor benchmark} A vendor database benchmark is used by
the database vendor during the production of the database management system.
This benchmark usually serves multiple purposes not just limited to the design
of the system. Of course, it is often used to highlight any performance
bottlenecks driving the design of the system internally but it usually doubles
up and acts as the knowledge base for the marketing of the system. Vendor
benchmarks are usually characterised by a more comprehensive suite of
tests to generate the insights capable of driving the direction of the
product \cite{PractitionersIntroduction}.

\paragraph{Industry-standard benchmark} An industry-standard benchmark is a set
benchmarking suite designed independently to any vendor or solution. It is
designed to allow for a fair comparison between different vendors and has been
shown to increase competition between vendors \cite{Wisconsin2}. As much of
this review will show, many industry-standard benchmarks have been developed
to give results for a wide range of applications of databases for much more
relevant and specialised results; and, although many benchmarks have similar
metrics \cite{SetQueryBenchmark, DebitCredit}, just selecting what metrics to
show consumers is not a trivial task \cite{DebitCredit}. When Gray's paper
\cite{BenchmarkHandbook} was written, it was noted that these benchmarks were
becoming so popular that vendors were also beginning to report their results
with their marketing.

\paragraph{Consumer-application benchmark} This type of benchmark refers to any
benchmarking that a customer would run, typically to choose between different
vendors for their application. This kind of testing can be critical for a
performance-sensitive application \cite{PractitionersIntroduction} and is often
done to test the performance of the database under a specific installation
profile \cite{DoingYourOwnBenchmark} or loads. This is a very specialised
requirements based benchmarking.

The review now turns to different domain-specific benchmarking of databases in
order to comment on and analyse any common structures found when designing
databases. This will help inform major design decisions of this project when
deciding what aspects to include in the benchmarking of the alternative join
syntax.

Despite the innumerable use cases for databases in the modern world, many
applications require and prioritise similar values when choosing a solution.
Furthermore, as most industrial-standard database benchmarks have been designed in
order to allow comparison for specific domain requirements, you will commonly
find database benchmarks that are designed with one of two different
applications in mind: \emph{transaction processing} or \emph{decision support}
\cite{PractitionersIntroduction}; it is worth mentioning that other application
types exist, however, such as \emph{document search} and \emph{direct marketing}
\cite{SetQueryBenchmark}. The application types of transaction processing and
decision support are so pervasive that they are commonly also used to partition
other application types, for instance OLTP (Online transaction processing) and
OLAP (Online analytical processing) are specialised for online processing but
share many comparative similarities as transaction processing and decision
support respectively \cite{OLTP-Oracle}.

This review will provide a brief overview of both
the main database application types, then focus more strongly on decision
support benchmarks as ad-hoc query processing is more heavily tested in these
benchmarks and thus more relevant to the project.

\subsection{Transaction processing}
Transaction processing is characterised by a large number of
update-intensive requests
\cite{PractitionersIntroduction}. It is clear that this type of environment
demands an emphasis on throughput and integrity. For instance, a bank would
likely have an \emph{online transaction processing system} or OLTP system in
place and it clear that the ability to deal with a large number of transactions
in a short period of time and for the accuracy if the information given is
paramount. There are many well known benchmarks to test these types of systems,
including \emph{DebitCredit}, \emph{TPC-C} and \emph{TPC-E} \cite{TPC-OLTP}.
These benchmarks usually measure transactions per second.

\subsubsection{Transaction integrity}
We briefly note what we mean by the integrity of a transaction. A transaction
simply is an input to the database that must be considered as one unit of work
\cite{ComputerScienceDictionary} and completed independently to any concurrent
actions occurring. This behaviour can be described a set of
properties typically remembered as the acronym \emph{ACID}
\cite{ComputerScienceDictionary, PractitionersIntroduction}.
\paragraph{atomicity}
\paragraph{consistency}
\paragraph{isolation}
\paragraph{durability}

\subsection{Decision processing}
\subsubsection{Wisconsin benchmark}

\subsubsection{Single-User Decision Support} % SUDS

\subsubsection{The Set Query Benchmark}

\subsection{Best practices benchmarking}
