\section{Synthetic database creation}
This section evaluates the design decisions and outcomes in creating a synthetic
database generator as outlined in \fref{sec:benchmark:syntheticdatabase}. This
project introduced a framework to generate database to fit a custom schema. The
benefits of synthetic data are vast and include the ability to define schemas
that are specialised in benchmarking and readability while controlling frequency
of values and other important properties.

Overall the result was quite different from other technologies available,
offering a low-level bare-bones solution. Many existing solutions equally support
qualitative data to quantitative with selling points based on the
\lstinline{Faker} python module. Although \lstinline{Faker} did not come to my
attention while designing the framework, it would not have been much use for the
\database{JOINBENCH} database in its final form as well. Additionally, much
infrastructure would still need to be made around the \lstinline{Faker} module
for easy exporting and specification, therefore it would not have saved much
time and allowed me to develop a more customised solution for the problem.
Advantages of the \lstinline{Faker} framework over my solution is the vast
amount of data available for attributes that were considered to be qualitative,
although there would still be time necessary in order to do due diligence on its
copyright and licensing creating further ethical considerations. The \lstinline{Faker} module has made interesting
design decisions, favouring a \lstinline{unique} attribute to composition for
uniqueness which itself comes with benefits and drawbacks. The \lstinline{Faker}
module does present interesting opportunities to enhance my solution however:
Using an adapter design pattern a faker object could easily be converted into
using the cell API and enrich my solution with a larger variety of data,
although I would accept the argument that it might be a waste of the set of rich
features implemented by the module. Using the \lstinline{Faker} module implicity
with other data synthesising modules that depend on
it, such as \lstinline{pydbgen}, can give a more complete solution even in
comparison to my framework. In essence, it uses the variety of data sources
provided by framework compiled into a variety of different outputs formats.
